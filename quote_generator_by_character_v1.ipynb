{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import sys\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input, Activation, Dense, Dropout\n",
    "from keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotables = pd.read_csv('author-quote.txt', delimiter='\\t', header=None)\n",
    "quotables = quotables.rename(columns={0:'author', 1:'quote'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24615</th>\n",
       "      <td>Melissa de la Cruz</td>\n",
       "      <td>Dark books do appeal to kids because they have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Anais Nin</td>\n",
       "      <td>The possession of knowledge does not kill the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18241</th>\n",
       "      <td>Joel Salatin</td>\n",
       "      <td>You wanna get diarrhoea? Eat industrial food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34626</th>\n",
       "      <td>Vincent D'Onofrio</td>\n",
       "      <td>Our show is different, because it's not about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18986</th>\n",
       "      <td>John Keats</td>\n",
       "      <td>Nothing ever becomes real till it is experienced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11791</th>\n",
       "      <td>Franz Kafka</td>\n",
       "      <td>One advantage in keeping a diary is that you b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13434</th>\n",
       "      <td>Guillaume Canet</td>\n",
       "      <td>You need to feed yourself with emotions and li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35626</th>\n",
       "      <td>William Makepeace Thackeray</td>\n",
       "      <td>Let a man who has to make his fortune in life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25179</th>\n",
       "      <td>Michelle Bachelet</td>\n",
       "      <td>During my lifetime, I realized that discrimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>Asghar Farhadi</td>\n",
       "      <td>There are those who simply want to live their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13930</th>\n",
       "      <td>Helen Garner</td>\n",
       "      <td>I like poking my nose into other people's lives.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28921</th>\n",
       "      <td>Richard Adams</td>\n",
       "      <td>The thinker dies, but his thoughts are beyond ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28956</th>\n",
       "      <td>Richard Dawkins</td>\n",
       "      <td>It's a horrible idea that God, this paragon of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29267</th>\n",
       "      <td>Robert Adamson</td>\n",
       "      <td>Well I guess the plan was to write poetry and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>Arthur Ashe</td>\n",
       "      <td>I accepted the face that as much as I want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>Genelia D'Souza</td>\n",
       "      <td>I'm a fast and impatient dresser, so I can't d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>Conrad Hall</td>\n",
       "      <td>With today's fast films, you can light the way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24565</th>\n",
       "      <td>Meister Eckhart</td>\n",
       "      <td>A human being has so many skins inside, coveri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>Isaac Newton</td>\n",
       "      <td>If I have done the public any service, it is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35157</th>\n",
       "      <td>Washington Irving</td>\n",
       "      <td>Love is never lost. If not reciprocated, it wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            author  \\\n",
       "24615           Melissa de la Cruz   \n",
       "1815                     Anais Nin   \n",
       "18241                 Joel Salatin   \n",
       "34626            Vincent D'Onofrio   \n",
       "18986                   John Keats   \n",
       "11791                  Franz Kafka   \n",
       "13434              Guillaume Canet   \n",
       "35626  William Makepeace Thackeray   \n",
       "25179            Michelle Bachelet   \n",
       "3144                Asghar Farhadi   \n",
       "13930                 Helen Garner   \n",
       "28921                Richard Adams   \n",
       "28956              Richard Dawkins   \n",
       "29267               Robert Adamson   \n",
       "2976                   Arthur Ashe   \n",
       "12325              Genelia D'Souza   \n",
       "7383                   Conrad Hall   \n",
       "24565              Meister Eckhart   \n",
       "15174                 Isaac Newton   \n",
       "35157            Washington Irving   \n",
       "\n",
       "                                                   quote  \n",
       "24615  Dark books do appeal to kids because they have...  \n",
       "1815   The possession of knowledge does not kill the ...  \n",
       "18241      You wanna get diarrhoea? Eat industrial food.  \n",
       "34626  Our show is different, because it's not about ...  \n",
       "18986  Nothing ever becomes real till it is experienced.  \n",
       "11791  One advantage in keeping a diary is that you b...  \n",
       "13434  You need to feed yourself with emotions and li...  \n",
       "35626  Let a man who has to make his fortune in life ...  \n",
       "25179  During my lifetime, I realized that discrimina...  \n",
       "3144   There are those who simply want to live their ...  \n",
       "13930   I like poking my nose into other people's lives.  \n",
       "28921  The thinker dies, but his thoughts are beyond ...  \n",
       "28956  It's a horrible idea that God, this paragon of...  \n",
       "29267  Well I guess the plan was to write poetry and ...  \n",
       "2976   I accepted the face that as much as I want to ...  \n",
       "12325  I'm a fast and impatient dresser, so I can't d...  \n",
       "7383   With today's fast films, you can light the way...  \n",
       "24565  A human being has so many skins inside, coveri...  \n",
       "15174  If I have done the public any service, it is d...  \n",
       "35157  Love is never lost. If not reciprocated, it wi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotables.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotables['len_quotes'] = quotables.quote.map(lambda s: len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quotes = list(quotables.quote + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_char = ['#', '$', '%', '(', ')', '=', ';' ,':',  '*', '+', '£' , '—','’']  \n",
    "quotes_cleaned = []\n",
    "\n",
    "for quote in quotes: \n",
    "    # remove unused character\n",
    "    for s_char in removed_char:\n",
    "        quote = quote.replace(s_char, ' ')\n",
    "    \n",
    "    # remove white space\n",
    "    pattern = re.compile(r'\\s{2,}')\n",
    "    quote = re.sub(pattern, ' ', quote)\n",
    "\n",
    "    quotes_cleaned.append(quote)\n",
    "\n",
    "text = ' '.join(quotes_cleaned)\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 753142\n"
     ]
    }
   ],
   "source": [
    "maxlen = 15\n",
    "step = 6\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for quote in quotes_cleaned:\n",
    "    for i in range(0, len(quote) - maxlen, step):\n",
    "        sentences.append(quote[i: i + maxlen])\n",
    "        next_chars.append(quote[i + maxlen])\n",
    "    sentences.append(quote[-maxlen:])\n",
    "    next_chars.append(quote[-1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you live to ',\n",
       " ' live to be a h',\n",
       " 'to be a hundred',\n",
       " 'a hundred, I wa',\n",
       " 'red, I want to ',\n",
       " ' want to live t',\n",
       " 'to live to be a',\n",
       " 'e to be a hundr',\n",
       " 'e a hundred min',\n",
       " 'ndred minus one',\n",
       " 'minus one day s',\n",
       " 'one day so I ne',\n",
       " 'y so I never ha',\n",
       " ' never have to ',\n",
       " ' have to live w',\n",
       " 'to live without',\n",
       " 'e without you.\\n',\n",
       " \"Promise me you'\",\n",
       " \"e me you'll alw\",\n",
       " \"ou'll always re\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((753142, 15, 73), (753142, 73), 73)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "## Model \n",
    "print('Build model...')\n",
    "input_sequences = Input((maxlen, len(chars)) , name=\"input_sequences\")\n",
    "lstm = Bidirectional(LSTM(256, return_sequences= True, input_shape=(maxlen, len(chars))), name = 'bidirectional')(input_sequences)\n",
    "lstm = Dropout(0.1, name = 'dropout_bidirectional_lstm')(lstm)\n",
    "lstm = LSTM(64, input_shape=(maxlen, len(chars)), name = 'lstm')(lstm)\n",
    "lstm = Dropout(0.1,  name = 'drop_out_lstm')(lstm)\n",
    "\n",
    "dense = Dense(15 * len(chars), name = 'first_dense')(lstm)\n",
    "dense = Dropout(0.1,  name = 'drop_out_first_dense')(dense)\n",
    "dense = Dense(5 * len(chars), name = 'second_dense')(dense)\n",
    "dense = Dropout(0.1,  name = 'drop_out_second_dense')(dense)\n",
    "dense = Dense(len(chars), name = 'last_dense')(dense)\n",
    "\n",
    "next_char = Activation('softmax', name = 'activation')(dense)\n",
    "\n",
    "model = Model([input_sequences], next_char)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_sequences (InputLayer) [(None, 15, 73)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 15, 512)           675840    \n",
      "_________________________________________________________________\n",
      "dropout_bidirectional_lstm ( (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                147712    \n",
      "_________________________________________________________________\n",
      "drop_out_lstm (Dropout)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "first_dense (Dense)          (None, 1095)              71175     \n",
      "_________________________________________________________________\n",
      "drop_out_first_dense (Dropou (None, 1095)              0         \n",
      "_________________________________________________________________\n",
      "second_dense (Dense)         (None, 365)               400040    \n",
      "_________________________________________________________________\n",
      "drop_out_second_dense (Dropo (None, 365)               0         \n",
      "_________________________________________________________________\n",
      "last_dense (Dense)           (None, 73)                26718     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 73)                0         \n",
      "=================================================================\n",
      "Total params: 1,321,485\n",
      "Trainable params: 1,321,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  51/5884 [..............................] - ETA: 37:02 - loss: 3.1037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5725e0f1aeb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit([x], y,\n\u001b[0;32m      2\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m          )\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\python37\\envs\\quoted\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([x], y,\n",
    "         batch_size=128,\n",
    "          epochs= 15\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "753142/753142 [==============================] - 959s 1ms/step - loss: 1.0823\n",
      "Epoch 2/2\n",
      "753142/753142 [==============================] - 1106s 1ms/step - loss: 1.0619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162988f60>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x], y,\n",
    "         batch_size=2048,\n",
    "          epochs= 2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "753142/753142 [==============================] - 969s 1ms/step - loss: 1.0616\n",
      "Epoch 2/2\n",
      "753142/753142 [==============================] - 980s 1ms/step - loss: 1.0574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c389208>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x], y,\n",
    "         batch_size=1024,\n",
    "          epochs= 2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_first_words = [bigram for bigram in [' '.join(word_tokenize(quote)[:2]) for quote in quotes] if len(bigram) <= maxlen]\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(sentence = None, diversity = 0.8):\n",
    "    \n",
    "    if not sentence: ## if input is null then sample two first word from dataset\n",
    "        random_index = np.random.randint(0, len(two_first_words))\n",
    "        sentence = two_first_words[random_index]\n",
    "        \n",
    "    if len(sentence) > maxlen:\n",
    "        sentence = sentence[-maxlen:]\n",
    "    elif len(sentence) < maxlen:\n",
    "        sentence = ' '*(maxlen - len(sentence)) + sentence\n",
    "        \n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    next_char = 'Empty'\n",
    "    total_word = 0 \n",
    "    \n",
    "    max_word = 15\n",
    "    \n",
    "    while ((next_char not in ['\\n', '.']) & (total_word <= 500)):\n",
    "    \n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        if next_char == ' ':\n",
    "           total_word += 1\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        I couldn't walk in the church.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         You don't have to take on my family.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      The legal songs on the same credit the long time, and you love a man without love, understanding.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Learn to know what the issue is my universe, how you do what they instead of beow.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       My motto with the down and amazing state in the classic and face it because I was a DeficiI I would learn all the unity.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       There is nothing without the past.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     After much things that I had a good way to be able to place the material things in the form of our tatence will go to see their show in it.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Once you will love you so introversions who'll say there is important thing that are something good into something to be simpling my feet I could be a none is the real of a time to stand for video from an energy people.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A successful sadness of the game of our controversy for how hear, is wrong in the time, and I got a short men.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Happiness is so such a house why can hasten before, what you take every time with my encouraged by Phose.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         If you are too lack friends and his things that are well in a books are not the volution of its heart that is a movie the banda used to always be a wanting to be long is confidentally good to one would be much more believe I do your poor.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_char.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_char.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
